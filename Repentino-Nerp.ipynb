{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(row):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', row).lower()\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "\n",
    "with gzip.open('dicionario_wb.dict.gz','rb') as fp:\n",
    "    dicionario = pickle.load(fp)\n",
    "    fp.close()\n",
    "    \n",
    "with gzip.open('lista_nomes_conjugado.dict.gz','rb') as fp:\n",
    "    lista_nomes_conjugado = pickle.load(fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagem(parte,total):\n",
    "        #parte = contador_nomes_retirados\n",
    "        #total = contador_nomes_HAREM\n",
    "        porcentagem = None\n",
    "        if total != 0:  \n",
    "            porcentagem = (parte / total)*100\n",
    "        \n",
    "        print(\"Porcentagem: \", porcentagem)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porcentagem_parc(parte,total):\n",
    "    porcentagem_parc = None\n",
    "    if total != 0:\n",
    "        porcentagem_parc = (parte/total)*100\n",
    "        \n",
    "    print(\"Porcentagem Parcial: \",porcentagem_parc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def remove_names(row, filename):\n",
    "    a = os.getcwd()+'/HAREM_EVO/HAREMRELREL.xml'\n",
    "    #f = open(a)\n",
    "    #golden_lines = f.readlines()\n",
    "    tree = ET.parse(a)\n",
    "    palavras_removidas = []\n",
    "    root = tree.getroot()\n",
    "    #for child in root:\n",
    "    #    print(child.get('DOCID'))\n",
    "    \n",
    "    ## Contadores\n",
    "    contador_nomes_HAREM = 0\n",
    "    contador_nomes_retirados = 0\n",
    "    contador_nomes_parcialmente_retirados = 0    \n",
    "    \n",
    "    \n",
    "    ## Separa cada uma das palavras\n",
    "    sentencas = row.split('\\n')\n",
    "    #print(sentencas)\n",
    "    j = 0\n",
    "    for s in sentencas:\n",
    "        palavras = s.split(' ')\n",
    "        ## Percorre todas as palavras\n",
    "        for i, p in enumerate(palavras):           \n",
    "\n",
    "            ## Remove acentos\n",
    "            ## Coloca palavras em minúsculas \n",
    "            ## Substitue caracteres especiais por espaço\n",
    "            p = remove_accents(p).lower()\n",
    "            n = re.sub(r'\\W',' ',p).strip()\n",
    "\n",
    "            #for palavra in dicionario:\n",
    "\n",
    "                # verifica se no inicio ou no fim há um nome\n",
    "                # remove do dicionario a palavra toda se houver \n",
    "                #if parte.rfind(nome) == (len(parte) - len(nome)): *** TEM QUE VERIFICAR A PALAVRAAAAAA\n",
    "                    #print ('NomeDic:', nome )\n",
    "                    #remove(parte.rfind(nome))    QUERO QUE REMOVA A PALAVRA DO DICIONARIO, NAO O NOME DELA!\n",
    "        \n",
    "\n",
    "\n",
    "            ## Substitue Nomes\n",
    "            if n in lista_nomes_conjugado:\n",
    "                #print ('nomes > ',n)\n",
    "                print(\"---Nome Removido---\")\n",
    "                print(n, p)\n",
    "                palavras[i] = p.lower().replace(n,'NoInfo')\n",
    "                palavras_removidas.append(n)\n",
    "            \n",
    "            else:\n",
    "                for parte in n.split(' '):\n",
    "\n",
    "                    #print(parte)\n",
    "                    ### Substitue nomes no meio de palavras (que não existem no dicionário)\n",
    "                    if not remove_accents(parte) in dicionario:\n",
    "                        #if len(parte) > 3:\n",
    "                            #print('No Dict: ',parte)\n",
    "                        for nome in lista_nomes_conjugado:\n",
    "                            in_list = False\n",
    "                            if parte == nome: #NÃO PEGA O NOME INTEIRO CORRETAMENTE D:\n",
    "                                p = p.replace(nome,'NoInfo')\n",
    "                                #print('Inteiro', parte,'*', nome)\n",
    "                                in_list = True\n",
    "                                palavras_removidas.append(nome)\n",
    "                        for nome in lista_nomes_conjugado:\n",
    "                            ## Remove nomes no meio da palavra\n",
    "                            #if len(nome) > 3 and parte.find(nome) >= 0:\n",
    "                            #    print('find:',parte,'|',nome)\n",
    "                            ## Remove nomes no início da palavra\n",
    "                            if len(nome) > 3 and parte.find(nome) == 0: \n",
    "                                #print('Inicio:',parte,'|',nome)\n",
    "                                if not in_list:\n",
    "                                    in_list = True\n",
    "                                    palavras_removidas.append(nome)\n",
    "                                p = p.replace(nome,'NoInfo ')\n",
    "                            ## Remove nomes no final da palavra\n",
    "                            if len(nome) > 3 and parte.rfind(nome) > 0 and parte.rfind(nome) == (len(parte)-len(nome)):\n",
    "                                #print('Final:', parte,'-',nome)\n",
    "                                if not in_list:\n",
    "                                    in_list = True\n",
    "                                    palavras_removidas.append(nome)\n",
    "                                p = p.replace(nome,' NoInfo ')\n",
    "\n",
    "                        palavras[i] = p.replace(nome,' NoInfo ')\n",
    "\n",
    "\n",
    "            ## Substitue os números de registros\n",
    "            num = re.findall(r'\\d*',p)[0]\n",
    "            if len(num) > 7:\n",
    "                #print (p)\n",
    "                palavras[i] = 'NoInfo'\n",
    "\n",
    "            ## Substitue o Leito\n",
    "            if len(num) >= 3 and palavras[i-1].lower() == 'leito:':\n",
    "                #print(p, palavras[i-1])\n",
    "                palavras[i] = 'NoInfo'\n",
    "        s = ' '.join(palavras)\n",
    "        \n",
    "        prev_find = s.find('NoInfo')\n",
    "\n",
    "        \n",
    "    #while prev_find != -1:\n",
    "    #Terminar de comparar os nomes retirados dos textos com os do HArem\n",
    "    palavras_removidas = set(palavras_removidas)\n",
    "    print('---- Nomes Removidos ----')\n",
    "    print(palavras_removidas)\n",
    "    for doc in root:\n",
    "        #print(\"Filename\", filename)\n",
    "        if doc.get('DOCID') == filename:\n",
    "            #print(\"DOCID\", filename)\n",
    "            for paragraph in doc:\n",
    "                for em in paragraph:\n",
    "                    if em.get(\"CATEG\") == \"PESSOA\" and em.get('TIPO') == \"INDIVIDUAL\":\n",
    "                        #remover acentos\n",
    "\n",
    "                        em_temp = re.sub(r'\\W',' ',em.text).strip()\n",
    "                        \n",
    "                        nomes = em_temp.split()\n",
    "                        \n",
    "                        # lista de nomes sem acento\n",
    "                        for nome in nomes:\n",
    "\n",
    "                            #p = remove_accents(p).lower()\n",
    "\n",
    "                            nome_sem_acento = remove_accents(nome).lower()\n",
    "\n",
    "                            contador_nomes_HAREM += len(nomes)\n",
    "\n",
    "                            \n",
    "\n",
    "                            #for nome in nomes:\n",
    "                            print(\"-----Comparando Nomes----\")\n",
    "                            print(nome)\n",
    "                            #print(palavras_removidas)\n",
    "                            for palavra_removida in palavras_removidas:\n",
    "                                if nome_sem_acento == palavra_removida.lower():\n",
    "                                    contador_nomes_retirados += 1\n",
    "                                    print(nome_sem_acento, \" |t \", palavra_removida)\n",
    "                                elif nome_sem_acento.find(palavra_removida.lower()) != -1:\n",
    "                                    contador_nomes_parcialmente_retirados += 1\n",
    "                                    print(nome_sem_acento, \" |p \", palavra_removida)\n",
    "            break\n",
    "                                                    \n",
    "            #for gl in golden_lines:\n",
    "            #    if gl.find('DOCID='):\n",
    "            #        doc_id = gl[gl.find('\"')+1:gl.findr('\"')]\n",
    "            #        print(doc_id)\n",
    "            #        if doc_id == filename:\n",
    "                        \n",
    "            #E aí comparar com cada palavras retirada em palavras_removidas para ver se está correta.\n",
    "            prev_find = s.find('NoInfo', prev_find+1)\n",
    "            j = j + 1\n",
    "        #break\n",
    "    \n",
    "    \n",
    "    print(\"Nomes no HAREM: \", contador_nomes_HAREM, \" | Nomes Retirados: \", contador_nomes_retirados, \" | Nomes Parcialmente Retirados: \", contador_nomes_parcialmente_retirados, \" |Número de Erros: \", contador_nomes_HAREM - contador_nomes_parcialmente_retirados - contador_nomes_retirados)     \n",
    "    \n",
    "    porcentagem(contador_nomes_retirados, contador_nomes_HAREM)\n",
    "    porcentagem_parc(contador_nomes_parcialmente_retirados, contador_nomes_HAREM)\n",
    "    \n",
    "    ## Une todas as palavras de volta\n",
    "    return ' '.join(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Nome Removido---\n",
      "vasconcelos vasconcelos,\n",
      "---Nome Removido---\n",
      "policial policial\n",
      "---Nome Removido---\n",
      "soraia soraia\n",
      "---Nome Removido---\n",
      "chaves chaves\n",
      "---Nome Removido---\n",
      "nicolau nicolau\n",
      "---Nome Removido---\n",
      "ivo ivo\n",
      "---Nome Removido---\n",
      "jose jose\n",
      "---Nome Removido---\n",
      "alicia alicia\n",
      "---Nome Removido---\n",
      "joaquim joaquim\n",
      "---Nome Removido---\n",
      "almeida almeida.\n",
      "---Nome Removido---\n",
      "vasconcelos vasconcelos,\n",
      "---Nome Removido---\n",
      "tiago tiago\n",
      "---Nome Removido---\n",
      "santos santos,\n",
      "---Nome Removido---\n",
      "jose jose\n",
      "---Nome Removido---\n",
      "antonio antonio\n",
      "---Nome Removido---\n",
      "sofia sofia\n",
      "---Nome Removido---\n",
      "jose jose\n",
      "---Nome Removido---\n",
      "eduardo eduardo.\n",
      "---Nome Removido---\n",
      "vasconcelos vasconcelos,\n",
      "---- Nomes Removidos ----\n",
      "{'vasconcelos', 'jose', 'almeida', 'sofia', 'eduardo', 'alicia', 'joaquim', 'pedro', 'soraia', 'santos', 'antonio', 'nicolau', 'ivo', 'tiago', 'chaves', 'policial'}\n",
      "-----Comparando Nomes----\n",
      "António\n",
      "antonio  |t  antonio\n",
      "-----Comparando Nomes----\n",
      "Pedro\n",
      "pedro  |t  pedro\n",
      "-----Comparando Nomes----\n",
      "Vasconcelos\n",
      "vasconcelos  |t  vasconcelos\n",
      "-----Comparando Nomes----\n",
      "Soraia\n",
      "soraia  |t  soraia\n",
      "-----Comparando Nomes----\n",
      "Chaves\n",
      "chaves  |t  chaves\n",
      "-----Comparando Nomes----\n",
      "Nicolau\n",
      "nicolau  |t  nicolau\n",
      "-----Comparando Nomes----\n",
      "Breyner\n",
      "-----Comparando Nomes----\n",
      "Ivo\n",
      "ivo  |t  ivo\n",
      "-----Comparando Nomes----\n",
      "Canelas\n",
      "-----Comparando Nomes----\n",
      "José\n",
      "jose  |t  jose\n",
      "-----Comparando Nomes----\n",
      "Raposo\n",
      "-----Comparando Nomes----\n",
      "Joaquim\n",
      "joaquim  |t  joaquim\n",
      "-----Comparando Nomes----\n",
      "de\n",
      "-----Comparando Nomes----\n",
      "Almeida\n",
      "almeida  |t  almeida\n",
      "-----Comparando Nomes----\n",
      "Josef\n",
      "josef  |p  jose\n",
      "-----Comparando Nomes----\n",
      "von\n",
      "-----Comparando Nomes----\n",
      "Sternberg\n",
      "-----Comparando Nomes----\n",
      "António\n",
      "antonio  |t  antonio\n",
      "-----Comparando Nomes----\n",
      "Pedro\n",
      "pedro  |t  pedro\n",
      "-----Comparando Nomes----\n",
      "Vasconcelos\n",
      "vasconcelos  |t  vasconcelos\n",
      "-----Comparando Nomes----\n",
      "Tiago\n",
      "tiago  |t  tiago\n",
      "-----Comparando Nomes----\n",
      "Santos\n",
      "santos  |t  santos\n",
      "-----Comparando Nomes----\n",
      "José\n",
      "jose  |t  jose\n",
      "-----Comparando Nomes----\n",
      "António\n",
      "antonio  |t  antonio\n",
      "-----Comparando Nomes----\n",
      "Loureiro\n",
      "-----Comparando Nomes----\n",
      "Tino\n",
      "-----Comparando Nomes----\n",
      "Navarro\n",
      "-----Comparando Nomes----\n",
      "Virgílio\n",
      "-----Comparando Nomes----\n",
      "Castelo\n",
      "-----Comparando Nomes----\n",
      "Custódia\n",
      "-----Comparando Nomes----\n",
      "Gallego\n",
      "-----Comparando Nomes----\n",
      "Sofia\n",
      "sofia  |t  sofia\n",
      "-----Comparando Nomes----\n",
      "Grilo\n",
      "-----Comparando Nomes----\n",
      "José\n",
      "jose  |t  jose\n",
      "-----Comparando Nomes----\n",
      "Eduardo\n",
      "eduardo  |t  eduardo\n",
      "-----Comparando Nomes----\n",
      "António\n",
      "antonio  |t  antonio\n",
      "-----Comparando Nomes----\n",
      "Pedro\n",
      "pedro  |t  pedro\n",
      "-----Comparando Nomes----\n",
      "Vasconcelos\n",
      "vasconcelos  |t  vasconcelos\n",
      "Nomes no HAREM:  94  | Nomes Retirados:  23  | Nomes Parcialmente Retirados:  1  |Número de Erros:  70\n",
      "Porcentagem:  24.46808510638298\n",
      "Porcentagem Parcial:  1.0638297872340425\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "a = os.getcwd()+'/HAREM_EVO/HAREMRELREL.xml'\n",
    "#f = open(a)\n",
    "#golden_lines = f.readlines()\n",
    "tree = ET.parse(a)\n",
    "palavras_removidas = []\n",
    "root = tree.getroot()\n",
    "    \n",
    "c = os.listdir(os.getcwd()+'/HAREM_EVO/')\n",
    "a = os.getcwd()+'/HAREM_EVO/'\n",
    "conteudo = []\n",
    "achou = False\n",
    "for p in c:\n",
    "    if p.endswith(\".txt\"):\n",
    "        file = open(a+p)\n",
    "        #print(p)\n",
    "        for doc in root:\n",
    "            if doc.get('DOCID') == p.replace('.txt', ''):\n",
    "                #print (doc)\n",
    "                achou = True\n",
    "                remove_names(file.read(), p.replace('.txt', ''))\n",
    "                break\n",
    "        #print(file.read())\"/textosnerp/\"\n",
    "        #conteudo.append(file.read())\n",
    "        file.close()\n",
    "    \n",
    "    if achou: break\n",
    "\n",
    "#print(conteudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antonio-Pedro tá pegando pedro e Antonio não. Tem que tirar o - e espaçar onde era o -."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evo = pd.read('nerp-crf.tar.gz')\n",
    "\n",
    "#evo.to_csv('nerp-crf.tar.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(conteudo[0])\n",
    "#for c in conteudo:\n",
    "#    print(remove_names(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in conteudo:\n",
    "    print(c)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porcentagem de Acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achar onde noinfo tem '<prop>' do lado\n",
    "\n",
    "# Apos os acréscimos de noInfo correto, incorreto e dos não identificados, pegar a soma de todos e fazer regra de 3\n",
    "# ou dividir o correto/total, incorreto/total e o naoID/total e contar como porcentagem, para cada texto e evolucao.\n",
    "\n",
    "#porcentagem = 100*(part, total);\n",
    "#    return 100*flutuador(part)/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.getcwd()+'/HAREM_EVO/HAREMNAOANOTADO.xml'\n",
    "tree = ET.parse(a)\n",
    "root = tree.getroot()\n",
    "for doc in root:\n",
    "    filename = doc.get('DOCID')\n",
    "    f = open(os.getcwd()+'/HAREM_EVO/'+filename+\".txt\", 'w')\n",
    "    for paragraph in doc:\n",
    "        f.write(paragraph.text.strip('\\n'))\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
